{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ogura/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import logging as lg\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import load_model,Model\n",
    "from keras.callbacks import ModelCheckpoint,LambdaCallback\n",
    "import json\n",
    "from pathlib import Path\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasNetInterface:\n",
    "    \n",
    "    def __init__(self,trained_epochs,result_dir,batch_size,valid_rate):\n",
    "        self.result_dir=result_dir\n",
    "        self.batch_size=batch_size\n",
    "        self.valid_rate=valid_rate\n",
    "        model_path=result_dir/f\"{self.create_flag()}/model_{trained_epochs:02d}.h5\"\n",
    "        model_path.parent.mkdir(exist_ok=True)\n",
    "        if model_path.exists():\n",
    "            self.trained_epochs=trained_epochs\n",
    "            lg.info(\"Loading the trained model...\")\n",
    "            self.model=self.load_model(model_path)\n",
    "            lg.info(\"Loaded.\")\n",
    "        else:\n",
    "            lg.info(\"Not found such a trained model.\")\n",
    "            lg.info(\"Creating new model...\")\n",
    "            self.trained_epochs=0\n",
    "            self.model=self.construct()\n",
    "            lg.info(\"Finished.\")\n",
    "    \n",
    "    \n",
    "    def load_model(self,model_path):\n",
    "        return load_model(str(model_path))\n",
    "    \n",
    "    def fit(self, X, y, epochs):\n",
    "        if self.trained_epochs >= epochs:\n",
    "            lg.info(\"This model has already been traiend up to {trained_epochs}\")\n",
    "        callbacks=self.create_callbacks()\n",
    "        self.model.fit(X,y,initial_epoch=self.trained_epochs,epochs=epochs,\n",
    "                       batch_size=self.batch_size,callbacks=callbacks,validation_split=self.valid_rate)\n",
    "        return self.model.history\n",
    "    \n",
    "    def save_model(self,save_path):\n",
    "        self.model.save(str(save_path))\n",
    "        \n",
    "    def create_callbacks(self):\n",
    "        model_path=self.result_dir / (self.create_flag()+\"/model_{epoch:02d}.h5\")\n",
    "        mcp=ModelCheckpoint(str(model_path))\n",
    "        hcp=LambdaCallback(on_epoch_end=lambda epoch,logs: self.save_history(epoch,logs))\n",
    "        return [mcp,hcp]\n",
    "    \n",
    "    def save_history(self,epoch,logs):\n",
    "        epoch+=1\n",
    "        history_path=self.result_dir/ f\"{self.create_flag()}/history_{epoch:02d}.h5\"\n",
    "        history=self.model.history.history\n",
    "        if len(history)==0:\n",
    "            history={k:[v] for k,v in logs.items()}\n",
    "        else:\n",
    "            for k,v in logs.items(): \n",
    "                history[k].append(v)\n",
    "        with history_path.open(\"w\") as f:\n",
    "            json.dump(history,f)\n",
    "        self.trained_epochs+=epoch\n",
    "            \n",
    "    def create_flag(self):\n",
    "        pass\n",
    "        \n",
    "    def construct(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasClassifierInterface(KerasNetInterface):\n",
    "    metrics=[\"accuracy\"]\n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.model.predict(X),axis=1)\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        return np.argmax(self.model.predict(X),axis=1)\n",
    "\n",
    "class KerasRegressorInterface(KerasNetInterface):\n",
    "    metrics=[\"mse\"]\n",
    "    def predict(self,X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(KerasClassifierInterface):\n",
    "    \n",
    "    def __init__(self,trained_epochs=0, result_dir=Path(\"result\"),valid_rate=0.3, batch_size=256, input_dim=784,\n",
    "                             med1_dim=300,med2_dim=100,output_dim=10,activation=\"relu\",\n",
    "                             loss='categorical_crossentropy',optimizer='rmsprop'):\n",
    "        self.loss=loss\n",
    "        self.optimizer=optimizer\n",
    "        self.input_dim=input_dim\n",
    "        self.med1_dim=med1_dim\n",
    "        self.med2_dim=med2_dim\n",
    "        self.output_dim=output_dim\n",
    "        self.activation=activation\n",
    "        super().__init__(trained_epochs,result_dir,batch_size,valid_rate)\n",
    "        \n",
    "    def construct(self):\n",
    "        inputs = Input(shape=(self.input_dim,))\n",
    "        x = Dense(self.med1_dim, activation=self.activation)(inputs)\n",
    "        x = Dense(self.med2_dim, activation=self.activation)(x)\n",
    "        predictions = Dense(self.output_dim, activation='softmax')(x)\n",
    "        model = Model(inputs=inputs, outputs=predictions)\n",
    "        model.compile(optimizer=self.optimizer, loss=self.loss,metrics=self.metrics)\n",
    "        return model\n",
    "    \n",
    "    def create_flag(self):\n",
    "        return f\"{self.input_dim}_{self.med1_dim}_{self.med2_dim}_{self.output_dim}_{self.activation}_{self.batch_size}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_mnist(x,y):\n",
    "    sample_num=x.shape[0]\n",
    "    x=x.reshape(sample_num, -1)\n",
    "    x= x.astype('float32')\n",
    "    x /= 255\n",
    "    y = to_categorical(y, 10)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train,y_train=reshape_mnist(x_train,y_train)\n",
    "x_test,y_test=reshape_mnist(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.3821 - acc: 0.8882 - val_loss: 0.1972 - val_acc: 0.9411\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1472 - acc: 0.9563 - val_loss: 0.1456 - val_acc: 0.9557\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0989 - acc: 0.9707 - val_loss: 0.1702 - val_acc: 0.9456\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0723 - acc: 0.9778 - val_loss: 0.1474 - val_acc: 0.9525\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0536 - acc: 0.9831 - val_loss: 0.1064 - val_acc: 0.9696\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0412 - acc: 0.9877 - val_loss: 0.1283 - val_acc: 0.9636\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0317 - acc: 0.9905 - val_loss: 0.1147 - val_acc: 0.9672\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.0990 - val_acc: 0.9734\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0182 - acc: 0.9948 - val_loss: 0.1143 - val_acc: 0.9713\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0142 - acc: 0.9958 - val_loss: 0.1152 - val_acc: 0.9716\n"
     ]
    }
   ],
   "source": [
    "hisotry=model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
